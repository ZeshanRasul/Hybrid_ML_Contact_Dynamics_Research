# Hybrid ML Contact Dynamics

## Motivation and Overview

This project is a proof of concept research investigation into how machine learning (ML) models can support and accelerate physics calculations in complex and computationally demanding real-time simulations.

While the ML models are not intended to replace numerical computations entirely, the models are intended to improve computational performance for simulating physics phenomena which are notoriously difficult to implement in real-time due to noise, stiffness and computational constraints.

The current achieved milestone investigates whether ML can improve the estimation of contact restitution under noisy, discretely sampled dynamics.

This project has produced an encouraging baseline from which further ML and physics systems can be simulated and evaluated. While modern analytic estimators degrade rapidly under noise and temporal uncertainty, the model created has proven ML systems can successfully exploit local temporal structure around contact events to recover physically meaningful parameters.

Building upon this foundation, the developed baseline will be extended to study hybrid ML potential for more challenging physical systems such as fluid dynamics simulations.

## Physical System and Ground Truth

The physical system of this milestone simulates 2D rigidbody collision. Specifically, multiple configurable runs are performed involving a 2D circle rigidbody under the force of gravity freefalling and colliding with an infinite plane.

Each run has a fixed coefficient of restitution $e \in (0, 1)$. The governing equations of the simulation involve physically accurate freefall equations, the impact law and realistic height decay used as ground truth values for evaluation of the ML model. These equations are as follows:

### Dynamics Equations

$g = -9.81$

$\dot{v} = g$

$\dot{y} = v$

### Impact Law

$v^+ = -ev^-$

### Height Decay

$\frac{h_k+1}{h_k} = e^2$

### Visual Plots

Figures 1-3 illustrate the ground truth dynamics of the system, including phase-space trajectory, position-time evolution and velocity-time evolution. Together, these plots confirm correct physical behaviour and highlight the discontinuous, noise-sensitive nature of impact event that motivate the use of temporal windowing and learned estimators as described throughout this document.

![Position-Time evolution plot](/hybrid_ml_contact_dynamics//docs/images/timevsposition.png)

Figure 1: Position vs Time

![Velocity-Time evolution plot](/hybrid_ml_contact_dynamics//docs/images/timevsvelocity.png)

Figure 2: Velocity vs Time

![Position-Velocity evolution plot](/hybrid_ml_contact_dynamics//docs/images/positionvsvelocity.png)

Figure 3: Phase Plot (Velocity vs Position)

## Data Generation and Trajectory Logging

Data is generated by a significant number of physics simulation runs, each one lasting for a fixed duration of discrete timesteps. Key data, particularly the full time series trajectory and contact occurences of the freefalling circle are logged and persisted. This data is then accessed to generate training data for the ML model.

A strong emphasis is placed on creating a controlled and deterministic experiment which can be replicated and reproduced. Persistance of key data is prioritised to ensure that offline and after the fact training of the ML model can be completed. Furthermore, visual analysis can easily be generated and performed indepedently from data generation, allowing for further analysis whenever the study requires.

The simulation is designed in a way to mirror closely that of real-time physics simulations, especially the common traits of discretised timesteps, limited observability and high possibility of noise within the data due to computational gaps arising from discrete timesteps.

## Noise Model and Temporal Windowing

Central to the goal of measuring real-time discretised physics simulations was the use of temporal windowing of contact events, along with the inclusion of Gaussian noise within the data windows. Real-time simulations such as games and interactive physics applications rarely have perfect information, often relying on short historical state windows.

As such, to ensure relevance, a temporal window of position and velocity data is logged and persisted for each simulation run. Configurable noise is then added to data within the temporal window, as well as index jittering in order to elude greater correctional potential from the learned model.

This technique of using noisy, temporal data allows the model to adapt to noisy data and detect discontinuities and irregularities in the data, with the goal of becoming better at generalising to more complicated data sets.

## Baseline Estimators

In order to ensure fair comparisons, all results compare the ML hybrid approach with an observed noisy estimator. Given the use of a noise in the dataset, the observed noisy estimator is the most realistic comparator to the ML approach.

An analytic oracle estimator exists within the system but is not used for final results stage comparisons. A benefit of having an oracle estimator with access to noiseless, ground truth simulation data is the opportunity to understand the upper bound of performance in a state of perfect information. While it is not used for direct performance analysis, it provides a useful insight into difficulty of estimation even when information is noiseless and clean.

The comparisons and analysis, on the other hand, utilise an estimator with access to the observed noisy data. That is, the same temporal windows exposed to the ML model, with the same noise applied. Given the jitter in the temporal window construction, this observed estimator provides a like for like comparison with regards to a purely analytical approach and the ML hybrid approach. As the observed estimator is exposed to noise, its performance degrades with the increase of noise and jitter. As shown in the results section, the use of the ML model is justified by its ability to improve and assist the analytical approach due to its learned predictions.

## Machine Learning Model

This achieves positive results with a relatively simple and straightforward ML model. The strategy initial proof of concept experiements have taken is to keep the model lightweight and easy to interpret, with a greater focus on effective data collection and system architecture, rather than a complex, difficult to understand model. It is likely as the complexity of experiments increase, so too will the complexity of the model. As such, a simple starting position is felt to be ideal to ensure model complexity doesn't increase too fast.

The model architecture is that of a multi-kayer perceptron (|MLP).It takes as input a 10-dimensional vector consisting of five velocity values and five position values, relating to a window around each contact event.

The architecture of the mdeol in terms of layers and activation functions is as follows:

- An input layer receiving 10 features
- Two hidden layers taking 36 and 16 features as input
- An output layer returning a single scalar value for the residual (the error between the observed value for resitution - e);

The model learns:
$r=e_{trueobs} - e_{obs}$

and using that learning, computes
$ \hat{e} = clip((e\_{obs}) + \alpha(r), 0, 1)$

where $\alpha$ is a parameter tuned during model validation.

This formulation of the residual ensures variance is reduced while also mirroring the real-time constraints of numerical methods of traditional physics simulation. It ensures that the ML model performs as a correction, rather than a replacement, of the analytic estimates.

## Training and Evaluation

The system generates training data from a large number of independents runs of the physics simulation. Current results are found from a run of 1,300 runs, each generating multiple contact events. Each run has a temporal window index jitter random within a given range.

The temporal windows of velocity and position are generated post-run and persisted in order to be loaded for model training at a later time. The training process randomly permutes and splits the dataset in train, validate and test splits.

The model uses a Mean Squared Error (MSE) loss function along with the Adam optimiser. During training, a small discrete sweep is performed over the residual gain parameter $\alpha$ on the validation dataset. This ensures that the optimal value for $\alpha$ is chosen which maintains stability while minimising error.

Performance is assessed primarily by comparing the noisy observed estimator $e_{obs}$ against the hybrid ML estimator $\hat{e}$. A clamp rate is also logged which shows the rate of predictions that fall outside of the physical bounds.

## Results

The charts below show the results of the model's performance compared against the observed noisy estimator. Together they show that the ML hybrid has great potential to provide corrections above and beyond the observed estimator baseline given its ability to improve sample accuracy.

Figure 4 shows the per-sample error change between the hybrid ML and baseline observed estimator on the test set. Negative values suggest an improvement by hybrid estimators performance relative to the baseline. With a significant proportion improved, shown by Figure 6 to be over 70% of samples, the ML hybrid approach clearly improves performance and overall robustness of the system.

![Per-Sample Error Change](/hybrid_ml_contact_dynamics//docs/images/deltasquarederror.png)

Figure 4: Per-Sample Error Change comparison of Baseline and ML Hybrid Estimators

Figure 5 shows the Empirical Cumulative Distribution Function (ECDF) of the squared error of the baseline and hybrid estimators on the test set. Smaller errors are to the left of the graph and although it is noted that the visuals show only relatively small improvements, the hybrid model shows almost entirely smaller errors than the baseline.

The ECDF of the baseline estimator elucidates an interesting insight in its behaviour. Notably, it shows a pronounced kink due to a concentration of samples with a similar error magnitude of 1e-07. This can be explained due to the noise and jitter applied to the data fed to the baseline. Although this same noise and jitter is fed to the hybrid model, the hybrid model partially smoothes this kink by redistributing probability mass. This observation suggests that the baseline estimator fails to some extent under jitter and noise whereas the hybrid estimator learns corrections which can distinguish the differences in these samples in a way the baseline cannot.

![Empirical Cumulative Distribution Function](/hybrid_ml_contact_dynamics//docs/images/ecdf.png)

Figure 5: Empirical Cumulative Distribution Function of Squared Error for Baseline and ML Hybrid Estimators

Figure 6 compares the per-sample squared error between the ML hybrid estimator and the baseline observed estimator which is fed the same noisy, temporal data as the ML model. The data points below the dashed line represent samples where the ML hybrid estimator improved upon the baseline estimator. It is clear that the ML hybrid estimator improves performance and robustness given the 70.2% of samples on which the ML hybrid estimator outperformed the baseline.

![Per-Sample Error Comparison](/hybrid_ml_contact_dynamics//docs/images/baselinevshybriderr.png)

Figure 6: Per-Sample Error Comparison between Observed Noisy Baseline Estimator and ML Hybrid model

## Discussion

## Next Steps

## How to Run
